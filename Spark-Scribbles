Reference video:-
https://www.youtube.com/watch?v=7ooZ4S7Ay6Y&t=1524s

Slides:-
https://www.youtube.com/redirect?v=7ooZ4S7Ay6Y&redir_token=GLhppjsOmi1_kM-PV7q2FTeFjzt8MTUzNzk3NzQzMUAxNTM3ODkxMDMx&event=video_description&q=https%3A%2F%2Fspark-summit.org%2Fwp-content%2Fuploads%2F2015%2F03%2FSparkSummitEast2015-AdvDevOps-StudentSlides.pdf

Caching an RDD :-
Caching an RDD will just a lazy transformation determine which rdd should be cached based on how many times we are reuisng the RDD.
The percentage of the performance increase depends on how much we are able to cache

Q : Where will cache RDD be stored ?
Ans:-

Q: How will spark work on per partition basis ?
Ans:-


Q:-What is a joined RDD and CassandraRDD?
Ans:-

White Paper on Sparks:-

https://www.usenix.org/legacy/event/hotcloud10/tech/full_papers/Zaharia.pdf

berkley white paper on RDD's
https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf

white paper on spark streaming
http://sigops.org/s/conferences/sosp/2013/papers/p423-zaharia.pdf

splitSize vs blockSize in hadoop
https://stackoverflow.com/questions/30549261/split-size-vs-block-size-in-hadoop

Recommended memory Usages:-
Use at most 75% of a machines memory for Spark
Minimum executor heap size should be 8Gb
Max executor heap size depends... may be 40GB(watchout for GC)
Memory Usage is greatly affected by storage level and serialization format
Decide how you want to manage the GC

-----------------------------------------------------------------------
How does spark decide the Job -> Stages -> Tasks

When will stages run in parallel ?

Will Tasks tun in parallel ?

How are partitions determined ?


Narrow vs Wide Tramsformations 
Narrow transformation :- narrow dependencies, where each partition of the parent RDD is used by at most one partition of the chid RDD
Wide transformation :- wide dependencies, where multiple child partitions may depend on it. (Should effectively cache RDD so that we are not involving shuffle many times)

----------------------------------------------------------------------
Scheduling Process 
RDD Objects -> DAG Scheduler -> Task Scheduler -> Executor

DAG Scheduler Submits each stage or parallel stages
Task Scheduler launches individual tasks and retry for failed tasks
Executor execute tasks store and serve blocks

-------------------------------------------------------------------------------
BroadCast Variables & Accumulators

Broadcast Variables :-
Send a large read-only lookup table to all the nodes, or send a large feature vector in a ML algorithm to all nodes 

Accumulators :-
count events that occur during job execution for edbugging purposes.
Example:- How many lines of the input file were blank? Or how many corrupt records were in the input dataset?

How does broadcast variables avoid shuffle ?
